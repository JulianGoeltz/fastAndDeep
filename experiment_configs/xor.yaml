dataset: xor
neuron_params:
  g_leak: 1.0
  leak: 0.0
  tau_syn: 1.0
  threshold: 1.0
network_layout:
  layers:
    - name: 'DelaySynaptic'
      delay_mean: 0.0
      delay_std: 0.05
      trainable: true
      monitor: true
    - name: 'EqualtimeLayer'
      size: 10
      weights_mean: 1.5
      weights_std: 1.8
      biases: [] #[1]
      max_num_missing_spikes: 0.3
      trainable: true
      monitor: true
    - name: 'BroadcastLayer'
    - name: 'EqualtimeLayer'
      size: 2
      weights_mean: 0
      weights_std: 1.8
      biases: [] #[1]
      max_num_missing_spikes: 0.0
      trainable: true
  n_inputs: 4
training_params:
  alpha: 0.005
  batch_size: 150
  batch_size_eval: 200
  beta: 1.
  enforce_cpu: False
  epoch_number: 300
  epoch_snapshots: [100, 200]
  learning_rate: 0.005
  lr_scheduler: {gamma: 0.95, step_size: 20, type: StepLR}
  max_dw_norm: 0.2
  max_num_missing_spikes: [0.3, 0.0]
  momentum: 0
  numpy_seed: 12345
  optimizer: adam
  print_step_percent: 5.0
  resolution: 0.01
  sim_time: 4.0
  torch_seed: 2000
  training_noise: {mean: 0.0, std_dev: 0.2}
  use_forward_integrator: false
  use_hicannx: false
  weight_bumping_exp: true
  weight_bumping_targeted: true
  weight_bumping_value: 0.0005
  xi: 0.2
